{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM1w+a4ZJ4PUnIuQDuGqMZw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1ucky40nc3/ml4me/blob/main/vision/frame-interpolation/film/run_film_frame-interpolation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run [FILM](https://github.com/google-research/frame-interpolation) Frame-Interpolation"
      ],
      "metadata": {
        "id": "De2DAmM-zu6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the Colab Notebook"
      ],
      "metadata": {
        "id": "KufFH3jHxYns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "eJsJ5NWMsRDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeBFvRE0q3fg"
      },
      "outputs": [],
      "source": [
        "# @title Clone the [FILM Repository](https://github.com/google-research/frame-interpolation)\n",
        "%cd /content\n",
        "!git clone https://github.com/google-research/frame-interpolation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install Python Requirements\n",
        "!pip install parameterized\n",
        "!pip install mediapy\n",
        "!pip install apache-beam\n",
        "!pip install google-cloud-bigquery-storage\n",
        "!pip install natsort\n",
        "!pip install gdown\n",
        "!pip install av\n",
        "!pip install einops"
      ],
      "metadata": {
        "id": "4RzJ4z6-rQ0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download the Pretrained Models\n",
        "\n",
        "# @markdown 1. Link this [Google Drive Folder](https://drive.google.com/drive/folders/1q8110-qp225asX3DQvZnfLfJPkCHmDpy?usp=sharing) into a your Google Drive\n",
        "\n",
        "# @markdown 2. Copy the Pre-trained Model Files to this Colab Instance (automatic)\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "# @markdown Provide the path in your GDrive to the pre-trained model files:\n",
        "gdrive_pretrained_model_dir = \"/content/gdrive/MyDrive/projects/ML4ME/vision/frame_interpolation/film/pretrained_models\" # @param {type: \"string\"}\n",
        "# @markdown Set the local path for a copy of the files:\n",
        "local_pretrained_models_base_dir = \"/content/\"\n",
        "local_pretrained_models_dir = os.path.join(local_pretrained_models_base_dir, \"pretrained_models\")\n",
        "\n",
        "# Try to skip this step if the local dir exists\n",
        "if not os.path.exists(local_pretrained_models_dir):\n",
        "    !mkdir -p $local_pretrained_models_base_dir\n",
        "    !cp -r $gdrive_pretrained_model_dir $local_pretrained_models_dir"
      ],
      "metadata": {
        "id": "LhfmK1Z8raAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Implement Utils\n",
        "\n",
        "from typing import List\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from base64 import b64encode\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import einops\n",
        "\n",
        "from IPython.display import HTML\n",
        "from IPython.display import display\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "VIDEO_MIME_TYPE_MAP = {\n",
        "    \".avi\": \"video/x-msvideo\",\n",
        "    \".mp4\": \"video/mp4\",\n",
        "    \".mpeg\": \"video/mpeg\"\n",
        "}\n",
        "\n",
        "\n",
        "def show_images(\n",
        "    paths: List[str],\n",
        "    data_url_prefix: str = \"data:image/png;base64,\",\n",
        "    image_width: int = 300,\n",
        "    sample_style: str = \"display:flex;flex-direction:column\",\n",
        "    filename_style: str = \"text-align:center;\"\n",
        ") -> None:\n",
        "    data = [open(i, \"rb\").read() for i in paths]\n",
        "    data_urls = [data_url_prefix + b64encode(i).decode() for i in data]\n",
        "\n",
        "    configs = (sample_style, image_width, filename_style)\n",
        "    sample = '<div stype=\"{}\"><img src=\"%s\" width={}/><p style=\"{}\">{}</p></div>'\n",
        "    display(HTML(\n",
        "        f\"\"\"\n",
        "        <div class=\"row\" style=\"display:flex;flex-wrap:wrap;\">\n",
        "            {''.join([sample.format(*configs, path) for path in paths])}\n",
        "        </div>\n",
        "        \"\"\" % tuple(data_urls)\n",
        "    ))\n",
        "\n",
        "\n",
        "def frames_to_video(\n",
        "    frames_pattern: str,\n",
        "    video_path: str,\n",
        "    fps: float=24.,\n",
        ") -> None:\n",
        "    video_dir = os.path.join(*os.path.split(video_path)[:-1])\n",
        "    os.makedirs(video_dir, exist_ok=True)\n",
        "\n",
        "    paths = sorted(glob.glob(frames_pattern))\n",
        "    pbar = tqdm(paths, desc=\"Reading frames\", total=len(paths))\n",
        "    video_array = torch.stack([\n",
        "        torchvision.io.read_image(p)\n",
        "        for p in pbar\n",
        "    ])\n",
        "    video_array = einops.rearrange(\n",
        "        video_array,\n",
        "        \"t c h w -> t h w c\"\n",
        "    )\n",
        "    torchvision.io.write_video(\n",
        "        video_path,\n",
        "        video_array,\n",
        "        fps=fps\n",
        "    )\n",
        "\n",
        "\n",
        "def show_video(\n",
        "    filename: str,\n",
        "    width: int=800,\n",
        "    autoplay: bool=False\n",
        ") -> None:\n",
        "    \"\"\"Display a video.\"\"\"\n",
        "    with open(filename, \"rb\") as file:\n",
        "        data = file.read()\n",
        "\n",
        "    mime = filename.split(\".\")[-1]\n",
        "    data = b64encode(data).decode()\n",
        "    data_url = f\"data:video/{mime};base64,{data}\"\n",
        "\n",
        "    autoplay = \"autoplay\" if autoplay else \"\"\n",
        "    html = f\"\"\"\n",
        "    <video width={width} controls {autoplay}>\n",
        "            <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\"\n",
        "    display(HTML(html))\n",
        "\n",
        "\n",
        "def pad(num: int, length: int, value: int=0) -> str:\n",
        "    num_pad = length - len(str(num))\n",
        "    padding = \"\".join([str(value)] * num_pad)\n",
        "    return f\"{padding}{num}\"\n",
        "\n",
        "\n",
        "def video_to_frames(\n",
        "    video_path: str,\n",
        "    frames_dir: str\n",
        ") -> None:\n",
        "    os.makedirs(frames_dir, exist_ok=True)\n",
        "    video_frames, _, _ = torchvision.io.read_video(\n",
        "        video_path,\n",
        "        output_format=\"TCHW\"\n",
        "    )\n",
        "    num_frames = video_frames.shape[0]\n",
        "    num_chars = len(str(num_frames))\n",
        "    pbar = tqdm(\n",
        "        enumerate(video_frames),\n",
        "        desc=\"Writing frames\",\n",
        "        total=num_frames\n",
        "    )\n",
        "    for i, frame in pbar:\n",
        "        filename = f\"frame_{pad(i, num_chars)}.png\"\n",
        "        path = os.path.join(frames_dir, filename)\n",
        "        torchvision.io.write_png(frame, path)"
      ],
      "metadata": {
        "id": "cWMGuyQgwQsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpolate!"
      ],
      "metadata": {
        "id": "BGiUp_7wxWSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Interpolate (once) between two frames\n",
        "%cd /content/frame-interpolation\n",
        "\n",
        "# @markdown Provide a starting frame for the interpolation\n",
        "frame1 = \"/content/frame-interpolation/photos/one.png\" # @param {type: \"string\"}\n",
        "# @markdown Give a target frame for the interpolation\n",
        "frame2 = \"/content/frame-interpolation/photos/two.png\" # @param {type: \"string\"}\n",
        "# @markdown Set a path for the interpolated frame\n",
        "output_frame = \"/content/frame-interpolation/photos/output_middle.png\" # @param {type: \"string\"}\n",
        "\n",
        "\n",
        "!python -m eval.interpolator_test \\\n",
        "   --frame1 $frame1 \\\n",
        "   --frame2 $frame2 \\\n",
        "   --model_path $local_pretrained_models_dir/film_net/Style/saved_model \\\n",
        "   --output_frame $output_frame\n",
        "\n",
        "show_images([frame1, output_frame, frame2])"
      ],
      "metadata": {
        "id": "IjQtC0ycugBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Interpolate (n-times) between frames\n",
        "%cd /content/frame-interpolation\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "# @markdown Provide the path to an input directory (as a glob pattern that finds directories with min. 2 frames):\n",
        "input_dir = \"/content/frame-interpolation/photos\" # @param {type: \"string\"}\n",
        "# @markdown Specify the number of interpolated frames:\n",
        "n_times_to_interpolate = 6 # @param {type: \"number\"}\n",
        "\n",
        "!python -m eval.interpolator_cli  \\\n",
        "   --pattern $input_dir \\\n",
        "   --model_path $local_pretrained_models_dir/film_net/Style/saved_model \\\n",
        "   --times_to_interpolate $n_times_to_interpolate \\\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown Decide if you want to create a video\n",
        "do_create_video = True # @param {type: \"boolean\"}\n",
        "if do_create_video:\n",
        "    # @markdown Set the FPS of the output video\n",
        "    fps = 24.0 # @param {type: \"number\"}\n",
        "    fps = float(fps)\n",
        "    # @markdown Give an output path for the video\n",
        "    video_path = \"/content/interpolated.mp4\" # @param {type: \"string\"}\n",
        "\n",
        "    frames_pattern = os.path.join(input_dir, 'interpolated_frames', \"*\")\n",
        "    frames_to_video(\n",
        "        frames_pattern,\n",
        "        video_path,\n",
        "        fps=fps,\n",
        "    )\n",
        "    show_video(video_path)"
      ],
      "metadata": {
        "id": "h2cAUPXsyRhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Interpolate (n-times) between video frames\n",
        "%cd /content/frame-interpolation\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "# @markdown Provide the path to a video file:\n",
        "video_path = \"/content/gdrive/MyDrive/projects/ML4ME/vision/frame_interpolation/film/video.mp4\" # @param {type: \"string\"}\n",
        "# @markdown Set an output directory for the video frames:\n",
        "frames_dir = \"/content/frames\"\n",
        "\n",
        "!rm -r $frames_dir\n",
        "video_to_frames(video_path, frames_dir)\n",
        "\n",
        "# @markdown Specify the number of interpolated frames:\n",
        "n_times_to_interpolate = 6 # @param {type: \"number\"}\n",
        "\n",
        "!python -m eval.interpolator_cli  \\\n",
        "   --pattern $frames_dir \\\n",
        "   --model_path $local_pretrained_models_dir/film_net/Style/saved_model \\\n",
        "   --times_to_interpolate $n_times_to_interpolate \\\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown Decide if you want to create a video\n",
        "do_create_video = True # @param {type: \"boolean\"}\n",
        "if do_create_video:\n",
        "    # @markdown Set the FPS of the output video\n",
        "    fps = 24.0 # @param {type: \"number\"}\n",
        "    fps = float(fps)\n",
        "    # @markdown Give an output path for the video\n",
        "    video_path = \"/content/interpolated.mp4\" # @param {type: \"string\"}\n",
        "\n",
        "    frames_pattern = os.path.join(frames_dir, 'interpolated_frames', \"*\")\n",
        "    frames_to_video(\n",
        "        frames_pattern,\n",
        "        video_path,\n",
        "        fps=fps,\n",
        "    )\n",
        "    show_video(video_path)"
      ],
      "metadata": {
        "id": "1c0BfQkusTxk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}