{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pop Music Transformer: Beat-based Modeling and Generation of Expressive Pop Piano Compositions\n",
        "---"
      ],
      "metadata": {
        "id": "2rjcJptxUG22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resources"
      ],
      "metadata": {
        "id": "Z-gI3tb0Bss1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ðŸ“ƒ [Paper](https://arxiv.org/abs/2002.00212)\n",
        "- ðŸ“š [Project Page](https://ailabs.tw/human-interaction/pop-music-transformer/)\n",
        "- ðŸŽ¬ [Examples](https://drive.google.com/open?id=1LzPBjHPip4S0CBOLquk5CNapvXSfys54)\n",
        "- ðŸ’» [Code](https://github.com/YatingMusic/remi)"
      ],
      "metadata": {
        "id": "r-QFQ8Z2B0QW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract"
      ],
      "metadata": {
        "id": "kxIgS8WdB4pQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Abstract](https://arxiv.org/pdf/2002.00212.pdf) â€” *A great number of deep learning based models have been recently proposed for automatic music composition. Among these models, the Transformer stands out as a prominent approach for generating expressive classical piano performance with a coherent structure of up to one minute. The model is powerful in that it learns abstractions of data on its own, without much human-imposed domain knowledge or constraints. In contrast with this general approach, this paper shows that Transformers can do even better for music modeling, when we improve the way a musical score is converted into the data fed to a Transformer model. In particular, we seek to impose a metrical structure in the input data, so that Transformers can be more easily aware of the beat-bar-phrase hierarchical structure in music. The new data representation maintains the flexibility of local tempo changes, and provides hurdles to control the rhythmic and harmonic structure of music. With this approach, we build a Pop Music Transformer that composes Pop piano music with better rhythmic structure than existing Transformer models.*\n"
      ],
      "metadata": {
        "id": "XquN7cwJB71R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authors"
      ],
      "metadata": {
        "id": "e0xuVVJzCTa-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yu-Siang Huang<sup>1</sup>,\n",
        "Yi-Hsuan Yang<sup>1</sup>\n",
        "<br>\n",
        "<sup>1</sup>*Taiwan AI Labs & Academia Sinica*<br>"
      ],
      "metadata": {
        "id": "zlzn77QiCVm2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Citation"
      ],
      "metadata": {
        "id": "dsj5eYU9GOuj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plain Text"
      ],
      "metadata": {
        "id": "fm5EA3BNGbV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "Yu-Siang Huang and Yi-Hsuan Yang. 2020. Pop Music Transformer: Beatbased Modeling and Generation of Expressive Pop Piano Compositions. In 28th ACM International Conference on Multimedia (MM â€™20), October 12â€“16, 2020, Seattle, WA, USA.. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3394171.3413671\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "fiqG3m7jGd5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BibTex"
      ],
      "metadata": {
        "id": "P1Q9b9jdGQbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "@article{DBLP:journals/corr/abs-2002-00212,\n",
        "  author    = {Yu{-}Siang Huang and\n",
        "               Yi{-}Hsuan Yang},\n",
        "  title     = {Pop Music Transformer: Generating Music with Rhythm and Harmony},\n",
        "  journal   = {CoRR},\n",
        "  volume    = {abs/2002.00212},\n",
        "  year      = {2020},\n",
        "  url       = {https://arxiv.org/abs/2002.00212},\n",
        "  eprinttype = {arXiv},\n",
        "  eprint    = {2002.00212},\n",
        "  timestamp = {Mon, 10 Feb 2020 15:12:57 +0100},\n",
        "  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-00212.bib},\n",
        "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "tTmEj7wvGVAV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2GaoSD_yFoc"
      },
      "source": [
        "# Setup the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHZhI6V7yIq4"
      },
      "source": [
        "## Install [MidiTok](https://github.com/Natooz/MidiTok)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9aAR0ohxfpC"
      },
      "outputs": [],
      "source": [
        "!pip install miditok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6H0EHE2yFCX"
      },
      "source": [
        "## Download the [REMI](https://github.com/YatingMusic/remi) dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0ZdEDqWySp1"
      },
      "outputs": [],
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1JUDHGrVYGyHtjkfI2vgR1xb2oU8unlI3/view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebXb44Tjyp7s"
      },
      "outputs": [],
      "source": [
        "!unzip data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsL2NmtOzz0H"
      },
      "source": [
        "## Install [fluidsynth](https://github.com/FluidSynth/fluidsynth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbyXXKHb0Ewm"
      },
      "outputs": [],
      "source": [
        "!apt-get install fluidsynth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6O-X71P7787"
      },
      "source": [
        "### Test fluidsynth with a sample from the REMI dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVh4C6ky88jP"
      },
      "source": [
        "#### Use the default soundfont"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqcPO90G00bd"
      },
      "outputs": [],
      "source": [
        "midi_file = \"/content/data/train/000.midi\"\n",
        "sound_font = \"/usr/share/sounds/sf2/FluidR3_GM.sf2\"\n",
        "out_filename = \"output\"\n",
        "out_wav = f\"{out_filename}.wav\"\n",
        "out_mp3 = f\"{out_filename}.mp3\"\n",
        "\n",
        "!fluidsynth $sound_font $midi_file -F $out_wav\n",
        "!ffmpeg -i $out_wav -acodec mp3 $out_mp3 -y\n",
        "\n",
        "from IPython.display import Audio\n",
        "Audio(out_mp3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc1KOYFP9B6D"
      },
      "source": [
        "#### Use a different soundfont"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCXDhqbA8Bjx"
      },
      "outputs": [],
      "source": [
        "!wget http://ftp.osuosl.org/pub/musescore/soundfont/Sonatina_Symphonic_Orchestra_SF2.zip\n",
        "!unzip Sonatina_Symphonic_Orchestra_SF2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5f66BtF8obi"
      },
      "outputs": [],
      "source": [
        "midi_file = \"/content/data/train/000.midi\"\n",
        "sound_font = \"Sonatina_Symphonic_Orchestra.sf2\"\n",
        "out_filename = \"output\"\n",
        "out_wav = f\"{out_filename}.wav\"\n",
        "out_mp3 = f\"{out_filename}.mp3\"\n",
        "\n",
        "!fluidsynth $sound_font $midi_file -F $out_wav\n",
        "!ffmpeg -i $out_wav -acodec mp3 $out_mp3 -y\n",
        "\n",
        "from IPython.display import Audio\n",
        "Audio(out_mp3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup up the `REMI` repository"
      ],
      "metadata": {
        "id": "-ANWtG0rMvz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/1ucky40nc3/remi.git\n",
        "%cd remi"
      ],
      "metadata": {
        "id": "qIQSGHGb9sp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install dependencies"
      ],
      "metadata": {
        "id": "dNsSRAdK980s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.1\n",
        "!pip install -U numpy==1.18.5"
      ],
      "metadata": {
        "id": "MY8mzIIU9zR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download pretrained checkpoints"
      ],
      "metadata": {
        "id": "mpDa_Zpq-A-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1gxuTSkF51NP04JZgTE46Pg4KQsbHQKGo/view\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1nAKjaeahlzpVAX0F9wjQEG_hL4UosSbo/view\n",
        "\n",
        "!mkdir pretrained\n",
        "!unzip REMI-tempo-checkpoint.zip -d pretrained\n",
        "!unzip REMI-tempo-chord-checkpoint.zip -d pretrained"
      ],
      "metadata": {
        "id": "zLk1GkLI-C6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "3BO9RrmLEx2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown Generate a .midi file\n",
        "%cd /content/remi\n",
        "!mkdir -p ./results\n",
        "\n",
        "checkpoint = \"./pretrained/REMI-tempo-checkpoint\" # @param {type: \"string\"}\n",
        "output_path = \"./results\" # @param {type: \"string\"}\n",
        "prompt = None # @param {type: \"string\"}\n",
        "n_target_bar = 16 # @param {type: \"number\"}\n",
        "temperature = 1.2 # @param {type: \"number\"}\n",
        "topk = 5 # @param {type: \"number\"}\n",
        "seed = 42 # @param {type: \"number\"}\n",
        "\n",
        "!python main.py \\\n",
        "    --checkpoint $checkpoint \\\n",
        "    --output_path $output_path \\\n",
        "    --seed $seed"
      ],
      "metadata": {
        "id": "CmLg3w1XEz71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Play the latest generated audio\n",
        "import os\n",
        "import glob\n",
        "\n",
        "if os.path.isfile(output_path):\n",
        "    midi_file = output_path\n",
        "else:\n",
        "    midi_files = glob.glob(os.path.join(output_path, \"*.midi\"))\n",
        "    mid_files = glob.glob(os.path.join(output_path, \"*.mid\"))\n",
        "    midi_files.extend(mid_files)\n",
        "    midi_file = sorted(midi_files)[-1]\n",
        "\n",
        "sound_font = \"/content/Sonatina_Symphonic_Orchestra.sf2\"\n",
        "out_filename = midi_file.split(\"/\")[-1].split(\".\")[0]\n",
        "out_wav = f\"{out_filename}.wav\"\n",
        "out_mp3 = f\"{out_filename}.mp3\"\n",
        "\n",
        "!fluidsynth $sound_font $midi_file -F $out_wav\n",
        "!ffmpeg -i $out_wav -acodec mp3 $out_mp3 -y\n",
        "\n",
        "from IPython.display import Audio\n",
        "Audio(out_mp3)"
      ],
      "metadata": {
        "id": "U13X-fhIGYov",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "prBVgRSqR1Fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/remi\n",
        "\n",
        "checkpoint = \"./pretrained/REMI-tempo-checkpoint\" # @param {type: \"string\"}\n",
        "data_dir = \"/content/data/train\" # @param {type: \"string\"}\n",
        "output_dir = \"./outputs\" # @param {type: \"string\"}\n",
        "num_epochs = 200 # @param {type: \"number\"}\n",
        "seed = 42 # @param {type: \"number\"}\n",
        "\n",
        "!python finetune.py \\\n",
        "    --checkpoint $checkpoint \\\n",
        "    --data_dir $data_dir \\\n",
        "    --num_epochs $num_epochs \\\n",
        "    --seed $seed"
      ],
      "metadata": {
        "id": "3K-HPET3G3Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kwYWmEwXQOXZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}