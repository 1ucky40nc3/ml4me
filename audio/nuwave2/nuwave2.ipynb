{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNvY8TovA_nc"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-gI3tb0Bss1"
      },
      "source": [
        "## Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-QFQ8Z2B0QW"
      },
      "source": [
        "- ðŸ“ƒ [Paper](https://arxiv.org/abs/2206.08545)\n",
        "- ðŸ“š [Project Page](https://mindslab-ai.github.io/nuwave2)\n",
        "- ðŸŽ¬ [Examples](https://mindslab-ai.github.io/nuwave2)\n",
        "- ðŸ’» [Code](https://github.com/mindslab-ai/nuwave2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxIgS8WdB4pQ"
      },
      "source": [
        "## Abstract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XquN7cwJB71R"
      },
      "source": [
        "[Abstract](https://arxiv.org/pdf/2206.08545.pdf) â€” *Conventionally, audio super-resolution models fixed the initial\n",
        "and the target sampling rates, which necessitate the model to be\n",
        "trained for each pair of sampling rates. We introduce NU-Wave\n",
        "2, a diffusion model for neural audio upsampling that enables\n",
        "the generation of 48 kHz audio signals from inputs of various\n",
        "sampling rates with a single model. Based on the architecture of NU-Wave, NU-Wave 2 uses short-time Fourier convolution (STFC) to generate harmonics to resolve the main failure\n",
        "modes of NU-Wave, and incorporates bandwidth spectral feature transform (BSFT) to condition the bandwidths of inputs\n",
        "in the frequency domain. We experimentally demonstrate that\n",
        "NU-Wave 2 produces high-resolution audio regardless of the\n",
        "sampling rate of input while requiring fewer parameters than\n",
        "other models. The official code and the audio samples are available at* https://mindslab-ai.github.io/nuwave2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0xuVVJzCTa-"
      },
      "source": [
        "## Authors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlzn77QiCVm2"
      },
      "source": [
        "Seungu Han<sup>1,2</sup>,\n",
        "Junhyeok Lee<sup>1</sup>\n",
        "<br>\n",
        "<sup>1</sup>*MINDsLab Inc., Republic of Korea,*<br>\n",
        "<sup>2</sup>*Seoul National University, Republic of Korea*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsj5eYU9GOuj"
      },
      "source": [
        "## Citation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm5EA3BNGbV6"
      },
      "source": [
        "### Plain Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiqG3m7jGd5t"
      },
      "source": [
        "\n",
        "```\n",
        "Han, Seungu, and Junhyeok Lee. \"NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates.\" arXiv preprint arXiv:2206.08545 (2022).\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1Q9b9jdGQbo"
      },
      "source": [
        "### BibTex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTmEj7wvGVAV"
      },
      "source": [
        "```\n",
        "@misc{https://doi.org/10.48550/arxiv.2206.08545,\n",
        "  doi = {10.48550/ARXIV.2206.08545},\n",
        "  url = {https://arxiv.org/abs/2206.08545, \n",
        "  author = {Han, Seungu and Lee, Junhyeok},\n",
        "  keywords = {Audio and Speech Processing (eess.AS), Machine Learning (cs.LG), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences}, \n",
        "  title = {NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates},\n",
        "  publisher = {arXiv},\n",
        "  year = {2022},\n",
        "  copyright = {arXiv.org perpetual, non-exclusive license}\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRPIuYBTTIHn"
      },
      "source": [
        "# Set up the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xCU1KKapaBW"
      },
      "outputs": [],
      "source": [
        "# @markdown Mount your Google Drive at `/content/gdrive`\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62s3o_oAoThi"
      },
      "outputs": [],
      "source": [
        "# @markdown Clone the repository\n",
        "!git clone --recursive https://github.com/mindslab-ai/nuwave2.git\n",
        "%cd nuwave2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku_vBvxDoaJV"
      },
      "outputs": [],
      "source": [
        "# @markdown Install requirements\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_QQLIHwTYeZ"
      },
      "source": [
        "## Prepare the [`VCTK`](https://datashare.ed.ac.uk/handle/10283/3443) dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gD8wJnoTud3"
      },
      "source": [
        "### Download from an official source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRknLj9sowLP"
      },
      "outputs": [],
      "source": [
        "# @markdown Download the dataset from a official source\n",
        "!wget https://datashare.ed.ac.uk/bitstream/handle/10283/3443/VCTK-Corpus-0.92.zip?sequence=2&isAllowed=y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgbb5_KYIOpv"
      },
      "outputs": [],
      "source": [
        "# @markdown Copy the dataset to your gdrive\n",
        "!cp VCTK-Corpus-0.92.zip /content/gdrive/MyDrive/datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jus_ivdtTxsW"
      },
      "source": [
        "### Download from your gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_6m_CCESeUd"
      },
      "outputs": [],
      "source": [
        "!cp /content/gdrive/MyDrive/datasets/VCTK-Corpus-0.92.zip VCTK-Corpus-0.92.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gTpwcFoplko"
      },
      "outputs": [],
      "source": [
        ",#@title ðŸ¤— Signal completion ðŸ“£ðŸŽ¶âœ¨\n",
        "\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://cdn.pixabay.com/download/audio/2021/08/04/audio_0625c1539c.mp3?filename=success-1-6297.mp3\").play()')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqMNI-LAT4n6"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ticU5awhVfX6"
      },
      "outputs": [],
      "source": [
        "vctk_dir = \"vctk\"\n",
        "%env VCTK_DIR=$vctk_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPtJ-oIgpDg0"
      },
      "outputs": [],
      "source": [
        "!mkdir -p $vctk_dir\n",
        "!unzip VCTK-Corpus-0.92.zip -d $vctk_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFfun3wISz5D"
      },
      "outputs": [],
      "source": [
        "# @markdown Remove the speakers `p280` and `p315`\n",
        "\n",
        "!rm -r $vctk_dir/txt/p280\n",
        "!rm -r $vctk_dir/wav48_silence_trimmed/p280\n",
        "!rm -r $vctk_dir/txt/p315\n",
        "!rm -r $vctk_dir/wav48_silence_trimmed/p315"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeoDPe9KU3zC"
      },
      "outputs": [],
      "source": [
        "# @title ### Modify the config dataset path\n",
        "%%writefile hparameter.yaml\n",
        "\n",
        "train:\n",
        "  batch_size: 12\n",
        "  lr: 2e-4\n",
        "  weight_decay: 0.00\n",
        "  num_workers: 8\n",
        "  gpus: 2 #ddp\n",
        "  opt_eps: 1e-9\n",
        "  beta1: 0.9\n",
        "  beta2: 0.99\n",
        "\n",
        "data:\n",
        "  timestamp_path: 'vctk-silence-labels/vctk-silences.0.92.txt'\n",
        "  base_dir: 'vctk/wav48_silence_trimmed/'\n",
        "  dir: 'vctk/wav48_silence_trimmed_wav/'\n",
        "  format: '*mic1.wav'\n",
        "  cv_ratio: (100./108., 8./108., 0.00) #train/val/test\n",
        "\n",
        "audio:\n",
        "  filter_length: 1024\n",
        "  hop_length: 256\n",
        "  win_length: 1024\n",
        "  sampling_rate: 48000\n",
        "  sr_min: 6000\n",
        "  sr_max: 48000\n",
        "  length: 32768 #32*1024 ~ 1sec\n",
        "\n",
        "arch:\n",
        "  residual_layers: 15 #\n",
        "  residual_channels: 64\n",
        "  pos_emb_dim: 512\n",
        "  bsft_channels: 64\n",
        "\n",
        "logsnr:\n",
        "  logsnr_min: -20.0\n",
        "  logsnr_max: 20.0\n",
        "\n",
        "dpm:\n",
        "  max_step: 1000\n",
        "  pos_emb_scale: 50000\n",
        "  pos_emb_channels: 128 \n",
        "  infer_step: 8\n",
        "  infer_schedule: \"torch.tensor([-2.6, -0.8, 2.0, 6.4, 9.8, 12.9, 14.4, 17.2])\"\n",
        "\n",
        "log:\n",
        "  name: 'nuwave2'\n",
        "  checkpoint_dir: 'checkpoint'\n",
        "  tensorboard_dir: 'tensorboard'\n",
        "  test_result_dir: 'test_sample/result'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTsAxmroV0ke"
      },
      "outputs": [],
      "source": [
        "!python utils/flac2wav.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-OY1SRkV7uz"
      },
      "source": [
        "# Train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4MKyrn6WTeM"
      },
      "outputs": [],
      "source": [
        "# @title Modify the config\n",
        "%%writefile hparameter.yaml\n",
        "\n",
        "train:\n",
        "  batch_size: 6\n",
        "  lr: 2e-4\n",
        "  weight_decay: 0.00\n",
        "  num_workers: 2\n",
        "  gpus: 1 #ddp\n",
        "  opt_eps: 1e-9\n",
        "  beta1: 0.9\n",
        "  beta2: 0.99\n",
        "\n",
        "data:\n",
        "  timestamp_path: 'vctk-silence-labels/vctk-silences.0.92.txt'\n",
        "  base_dir: 'vctk/wav48_silence_trimmed/'\n",
        "  dir: 'vctk/wav48_silence_trimmed_wav/'\n",
        "  format: '*mic1.wav'\n",
        "  cv_ratio: (100./108., 8./108., 0.00) #train/val/test\n",
        "\n",
        "audio:\n",
        "  filter_length: 1024\n",
        "  hop_length: 256\n",
        "  win_length: 1024\n",
        "  sampling_rate: 48000\n",
        "  sr_min: 6000\n",
        "  sr_max: 48000\n",
        "  length: 32768 #32*1024 ~ 1sec\n",
        "\n",
        "arch:\n",
        "  residual_layers: 15 #\n",
        "  residual_channels: 64\n",
        "  pos_emb_dim: 512\n",
        "  bsft_channels: 64\n",
        "\n",
        "logsnr:\n",
        "  logsnr_min: -20.0\n",
        "  logsnr_max: 20.0\n",
        "\n",
        "dpm:\n",
        "  max_step: 1000\n",
        "  pos_emb_scale: 50000\n",
        "  pos_emb_channels: 128 \n",
        "  infer_step: 8\n",
        "  infer_schedule: \"torch.tensor([-2.6, -0.8, 2.0, 6.4, 9.8, 12.9, 14.4, 17.2])\"\n",
        "\n",
        "log:\n",
        "  name: 'nuwave2'\n",
        "  checkpoint_dir: 'checkpoint'\n",
        "  tensorboard_dir: 'tensorboard'\n",
        "  test_result_dir: 'test_sample/result'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0Hp1S8WW4eS"
      },
      "outputs": [],
      "source": [
        "# @markdown Start a `TensorBoard`\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=./tensorboard --bind_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdDiZdEdWdQ9"
      },
      "outputs": [],
      "source": [
        "!python trainer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTD8ZHiWX0pT"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torchtext==0.11.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xssu1-BuX2w3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "FRPIuYBTTIHn",
        "v-OY1SRkV7uz"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "89a17144586464b8ad29eb738f315503f40ccf5acd27c4498b60cfa1b9f49e6c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
