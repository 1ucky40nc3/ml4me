{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNvY8TovA_nc"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# FIGARO: Generating Symbolic Music with Fine-Grained Artistic Control\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-gI3tb0Bss1"
      },
      "source": [
        "## Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-QFQ8Z2B0QW"
      },
      "source": [
        "- ðŸ“ƒ [Paper](https://arxiv.org/abs/2201.10936)\n",
        "- ðŸ“š [Project Page](https://github.com/dvruette/figaro)\n",
        "- ðŸŽ¬ [Examples](https://soundcloud.com/user-751999449/sets/figaro-generating-symbolic-music-with-fine-grained-artistic-control)\n",
        "- ðŸ’» [Code](https://github.com/dvruette/figaro)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxIgS8WdB4pQ"
      },
      "source": [
        "## Abstract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XquN7cwJB71R"
      },
      "source": [
        "[Abstract](https://arxiv.org/pdf/2201.10936.pdf) â€” *Generating music with deep neural networks has been an area of active research in recent years. While the quality of generated samples has been steadily increasing, most methods are only able to exert minimal control over the generated sequence, if any. We propose the self-supervised description-to-sequence task, which allows for fine-grained controllable generation on a global level. We do so by extracting high-level features about the target sequence and learning the conditional distribution of sequences given the corresponding high-level description in a sequence-to-sequence modelling setup. We train FIGARO (FIne-grained music Generation via Attention-based, RObust control) by applying description-to-sequence modelling to symbolic music. By combining learned high level features with domain knowledge, which acts as a strong inductive bias, the model achieves state-of-the-art results in controllable symbolic music generation and generalizes well beyond the training distribution.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0xuVVJzCTa-"
      },
      "source": [
        "## Authors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlzn77QiCVm2"
      },
      "source": [
        "Dimitri von Rutte<sup>1</sup>,\n",
        "Luca Biggio<sup>1</sup>,\n",
        "Yannic Kilcher<sup>1</sup>,\n",
        "Thomas Hofmann<sup>1</sup>\n",
        "\n",
        "<br>\n",
        "<sup>1</sup>Department of Computer Science, ETH ZÃ¼rich, ZÃ¼rich,\n",
        "Switzerland<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsj5eYU9GOuj"
      },
      "source": [
        "## Citation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm5EA3BNGbV6"
      },
      "source": [
        "### Plain Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiqG3m7jGd5t"
      },
      "source": [
        "\n",
        "```\n",
        "Liu, J., Dong, Y., Cheng, Z., Zhang, X., Li, X., Yu, F., & Sun, M. (2022). Symphony Generation with Permutation Invariant Language Model. ArXiv, abs/2205.05448.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1Q9b9jdGQbo"
      },
      "source": [
        "### BibTex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTmEj7wvGVAV"
      },
      "source": [
        "```\n",
        "@article{https://doi.org/10.48550/arxiv.2205.05448,\n",
        "  doi = {10.48550/ARXIV.2205.05448},\n",
        "  url = {https://arxiv.org/abs/2205.05448},\n",
        "  author = {Liu, Jiafeng and Dong, Yuanliang and Cheng, Zehua and Zhang, Xinran and Li, Xiaobing and Yu, Feng and Sun, Maosong},\n",
        "  keywords = {Sound (cs.SD), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},\n",
        "  title = {Symphony Generation with Permutation Invariant Language Model},\n",
        "  publisher = {arXiv},\n",
        "  year = {2022},\n",
        "  copyright = {Creative Commons Attribution 4.0 International}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlYT5i9hYeqr"
      },
      "source": [
        "# Set up the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN4u055lYhYo"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHzQDCglYNHZ"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/1ucky40nc3/figaro.git\n",
        "%cd figaro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoABHq5kiaes"
      },
      "outputs": [],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GywlgbjXYYiJ"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADg3b3_MYmS6"
      },
      "source": [
        "## Prepare the [`Lakh MIDI`](https://github.com/dvruette/figaro) dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKR8U3DaYuAQ"
      },
      "outputs": [],
      "source": [
        "!wget http://hog.ee.columbia.edu/craffel/lmd/lmd_full.tar.gz\n",
        "!tar -xzf lmd_full.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NoOlK7jYytR"
      },
      "source": [
        "## Download Pre-Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5mzHRiRY1Le"
      },
      "outputs": [],
      "source": [
        "!wget -O checkpoints.zip https://polybox.ethz.ch/index.php/s/a0HUHzKuPPefWkW/download\n",
        "!unzip checkpoints.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x3Ak2KUY3BE"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3c8oE6iY4FT"
      },
      "outputs": [],
      "source": [
        "%env MODEL=figaro-expert\n",
        "%env BATCH_SIZE=128\n",
        "%env TARGET_BATCH_SIZE=512\n",
        "%env CONTEXT_SIZE=128\n",
        "\n",
        "!python src/train.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "89a17144586464b8ad29eb738f315503f40ccf5acd27c4498b60cfa1b9f49e6c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
